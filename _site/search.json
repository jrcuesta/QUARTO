[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "José Ramón Cuesta",
    "section": "",
    "text": "This is the personal blog of José Ramón Cuesta about the use of chemometric tools available in R to study the Near Infrared spectroscopy and develop models with the spectra and reference values."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NIR-CHEMOMETRICS",
    "section": "",
    "text": "PLS - NIT tutorial (part 13)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nPLS\n\n\n\n\nDeveloping our firsts PLS Models\n\n\n\n\n\n\nJan 9, 2023\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nPCA - NIT tutorial (part 12)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nPCA\n\n\n\n\nLooking for outliers in the intercorrelation plots\n\n\n\n\n\n\nDec 19, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nPCA - NIT tutorial (part 11)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nPCA\n\n\n\n\nChecking how the RMD is related to parameters extreme samples\n\n\n\n\n\n\nDec 16, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nPCA - NIT tutorial (part 10)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nPCA\n\n\n\n\nlooking for outliers with Mahalanobis distances in the Principal Components Space\n\n\n\n\n\n\nNov 17, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nPCA - NIT tutorial (part 9)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nPCA\n\n\n\n\nContinue exploring the Principal Component Analysis\n\n\n\n\n\n\nNov 2, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nPCA - NIT tutorial (part 8)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nPCA\n\n\n\n\nRunning Principal Components Analysis on the spectra matrix\n\n\n\n\n\n\nOct 21, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nNear Infrared Transmitance Tutorial (part 7)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nRemoving scatter\n\n\nMath-treatments\n\n\n\n\nWe can use derivatives to remove baseline offsets, alone or combined with other scatter math treatments\n\n\n\n\n\n\nOct 19, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nNear Infrared Transmitance Tutorial (part 6)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nRemoving scatter\n\n\nMath-treatments\n\n\n\n\nThe use of linear or quadratic detrend alone or combined with SNV will be treated in this post\n\n\n\n\n\n\nOct 14, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nNear Infrared Transmitance Tutorial (part 5)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nRemoving scatter\n\n\nMath-treatments\n\n\n\n\nThis time we use the Multiple Scatter Correction algorithm ro remove the scatter\n\n\n\n\n\n\nOct 5, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nNear Infrared Transmitance Tutorial (part 4)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nRemoving scatter\n\n\nMath-treatments\n\n\n\n\nAlong the coming post we will several math treatments trying to improve the correlation between the predictors and the outcomes. In this one SNV\n\n\n\n\n\n\nOct 3, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nNear Infrared Transmitance Tutorial (part 3)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\nCollinearity\n\n\n\n\nLet´s check the correlation between the outcomes, between the predictors and between outcomes and predictors\n\n\n\n\n\n\nSep 29, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nNear Infrared Transmitance Tutorial (part 2)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\n\n\nLet use tidyverse to see the spectra and histograms\n\n\n\n\n\n\nSep 28, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNear Infrared Transmitance Tutorial (part 1)\n\n\n\n\n\n\n\nR\n\n\nNIT Tutorial\n\n\n\n\nPlot the near infrared transmitance spectra of meat samples and have a look to the histograms of the main parameters using classic R code\n\n\n\n\n\n\nSep 26, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2022\n\n\nJosé Ramón Cuesta\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/NIT_tutorial_1/NIT_tutorial_1.html",
    "href": "posts/NIT_tutorial_1/NIT_tutorial_1.html",
    "title": "Near Infrared Transmitance Tutorial (part 1)",
    "section": "",
    "text": "This is the first post about how to work with Near Infrared Transmitance spectra, using the data available in the package Caret and called “tecator”. Just consult the information about this data in R\n\nlibrary(caret)\n\nWhen loading tecator, we have two data tables: “absorp” and “endpoints” with the spectra and reference values for the parameters “water”, “fat” and “protein” for the 215 meat samples.\n\ndata(tecator)\nls()\n\n[1] \"absorp\"    \"endpoints\"\n\n\nThe spectra data is in the “absorp” table which is a matrix of 215 rows (number of samples) ,and 100 columns (number of wavelengths ), so we can give names to the columns of “absorp” matrix.\n\ncolnames(absorp) <- seq(850, 1048, by = 2)\n\nWe can have a look to the spectra and see its appearance:\n\nmatplot(colnames(absorp), t(absorp), type = \"l\", ylab = \"Absorbance\", xlab = \"wavelength (nm)\", main = \"Raw meat spectra\")\n\n\n\n\nFigure 1: Raw spectra.\n\n\n\n\nWe can see the differences in absorbance for every spectra due to the scatter, differences in the pathlength and other physical reasons. This is something we have to work on to remove it and try to see as better as possibles the chemical changes due to the differences in moisture, fat and protein, which are the parameter we want to build models.\nThe “endpoints” table has the reference values for the parameters of interest (Moisture, Fat and Protein). It is important to have a look to the parameters distribution, so we can use for this the histogram, but first lets give names to the parameters matrix.\nAs we can see we have not coloumn names\n\ncolnames(endpoints)\n\nNULL\n\n\nSo we can give them names:\n\ncolnames(endpoints) <- c(\"Moisture\", \"Fat\", \"Protein\")"
  },
  {
    "objectID": "posts/NIT_tutorial_1/NIT_tutorial_1.html#looking-to-the-parameters-distribution",
    "href": "posts/NIT_tutorial_1/NIT_tutorial_1.html#looking-to-the-parameters-distribution",
    "title": "Near Infrared Transmitance Tutorial (part 1)",
    "section": "Looking to the parameters distribution",
    "text": "Looking to the parameters distribution\nLet´s see the Moisture histogram\n\nhistogram(endpoints[ , 1], xlab = \"Moisture content\", main =\"Histogram Moisture\", col = \"blue\")\n\n\n\n\nFigure 2: Moisture histogram.\n\n\n\n\nNow the Fat histogram\n\nhistogram(endpoints[ , 2], xlab = \"Fat content\", main =\"Histogram Fat\", col = \"grey\")\n\n\n\n\nFigure 3: Fat histogram.\n\n\n\n\nand finally the Protein histogram\n\nhistogram(endpoints[ , 3], xlab = \"Protein content\", main =\"Histogram Protein\", col = \"red\")\n\n\n\n\nFigure 4: Protein histogram.\n\n\n\n\nWe can create a data frame called “tecator” with the “endpoints” and “absorp” matrices\n\ntecator <- data.frame(endpoints)\ntecator$spec <- absorp\n\nNow let´s save the dataframe to use in another post:\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws1.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_10/NIT_tutorial_10.html",
    "href": "posts/NIT_tutorial_10/NIT_tutorial_10.html",
    "title": "PCA - NIT tutorial (part 10)",
    "section": "",
    "text": "First of all let´s load the previous workspace:\nand the libraries that we are going to use:\nIn this post we start looking for outiers, or samples which look different than the majority. Finally we have decided to select three principal components, for that reason is much easier the graphical representation due to we can use 2D or 3D graphics. One of the most common methods is to draw an ellipsoid in the Principal Component space and the samples which fall outside the ellipsoid are considered as outliers.\nAs we remember the score matrix is tecator_pc$x[ , 1:3], and we can see all the posible scores planes with:"
  },
  {
    "objectID": "posts/NIT_tutorial_10/NIT_tutorial_10.html#mahalanobis-distances-ellipses",
    "href": "posts/NIT_tutorial_10/NIT_tutorial_10.html#mahalanobis-distances-ellipses",
    "title": "PCA - NIT tutorial (part 10)",
    "section": "Mahalanobis distances ellipses",
    "text": "Mahalanobis distances ellipses\nWe can create ellipses on every plane with the average spectrum in the center. As we can see the ratio change depending of the PC number and its variability.\n\ndrawMahal(tecator_pc$x[ , 1:2], center = apply(tecator_pc$x[ , 1:2], 2, mean), \n          covariance = cov(tecator_pc$x[ , 1:2]), quantile = 0.975 )\n\n\n\ndrawMahal(tecator_pc$x[ , c(1,3)], center = apply(tecator_pc$x[ , c(1,3)], 2, mean), \n          covariance = cov(tecator_pc$x[ , c(1,3)]), quantile = 0.975 )\n\n\n\ndrawMahal(tecator_pc$x[ , c(2,3)], center = apply(tecator_pc$x[ , c(2,3)], 2, mean), \n          covariance = cov(tecator_pc$x[ , c(2,3)]), quantile = 0.975 )\n\n\n\n\nThe final Mahalanobis distance is calculated for the three principal components, so we have to proceed with a calculation which use the complete score matrix (the three PC selected). Let`s keep the distances (classical and robust) value in an object called “res”.\n\nres <- Moutlier(tecator_pc$x[ , 1:3])\n\n\n\n\nNow we can take apart the samples with distance higher than 3, and make a subset with them:\n\nmd_out <-  which(res$md > 3)\nmd_out <- tecator_pc$x[md_out, ]"
  },
  {
    "objectID": "posts/NIT_tutorial_10/NIT_tutorial_10.html#looking-to-the-mahalanobis-distance-outliers",
    "href": "posts/NIT_tutorial_10/NIT_tutorial_10.html#looking-to-the-mahalanobis-distance-outliers",
    "title": "PCA - NIT tutorial (part 10)",
    "section": "Looking to the mahalanobis distance outliers",
    "text": "Looking to the mahalanobis distance outliers\nLet`s mark these outlier samples in the ellipses we have seen before:\n\ndrawMahal(tecator_pc$x[ , 1:2], center = apply(tecator_pc$x[ , 1:2], 2, mean), \n          covariance = cov(tecator_pc$x[ , 1:2]), quantile = 0.975, col = \"grey\" )\n\npoints(x = md_out[ , 1],\n       y = md_out[ , 2],\n       pch = 16, \n       col = \"red\")\n\ntext(md_out[ , 1], md_out[ , 2], label = rownames(md_out), pos = 2)\n\n\n\n\nAs we can see in this first plot many of the samples with hight Mahalanobis distance are inside the ellipse (131, 4, 174, 5, 7, 11, 132 and 44)\n\ndrawMahal(tecator_pc$x[ , c(1,3)], center = apply(tecator_pc$x[ , c(1,3)], 2, mean), \n          covariance = cov(tecator_pc$x[ , c(1,3)]), quantile = 0.975, col = \"grey\" )\n\npoints(x = md_out[ , 1],\n       y = md_out[ , 3],\n       pch = 16, \n       col = \"red\")\n\ntext(md_out[ , 1], md_out[ , 3], label = rownames(md_out), pos = 2)\n\n\n\n\nIn this plot all the samples that were into the ellipse on the first plot are now outside.\n\ndrawMahal(tecator_pc$x[ , c(2,3)], center = apply(tecator_pc$x[ , c(2,3)], 2, mean), \n          covariance = cov(tecator_pc$x[ , c(2,3)]), quantile = 0.975, col = \"grey\" )\npoints(x = md_out[ , 2],\n       y = md_out[ , 3],\n       pch = 16, \n       col = \"red\")\ntext(md_out[ , 2], md_out[ , 3], label = rownames(md_out), pos = 2)"
  },
  {
    "objectID": "posts/NIT_tutorial_10/NIT_tutorial_10.html#looking-to-cubes-in-3d",
    "href": "posts/NIT_tutorial_10/NIT_tutorial_10.html#looking-to-cubes-in-3d",
    "title": "PCA - NIT tutorial (part 10)",
    "section": "Looking to cubes in 3D",
    "text": "Looking to cubes in 3D\nOn the third plot again same samples are on and other out, so we have to take into acount that the Mahalanobis distance is a combination distance of the three planes, so we have to look at all of them at the same time and the better way to do it (in the case of three PCs), is in a cube.\n\ntecator_pc_3d <- scatterplot3d(tecator_pc$x[ , 1],\n              tecator_pc$x[ , 2],\n              tecator_pc$x[ , 3], \n              xlab = \"PC1\",\n              ylab = \"PC2\",\n              zlab = \"PC3\",\n              color = rgb(red=0.5, green=0.5, blue=0.5, alpha = 0.5),\n              pch = 16, angle =50)\n\ntecator_pc_3d$points3d(md_out[ , 1],\n                       md_out[ , 2],\n                       md_out[ , 3], \n                       pch = \"X\",\n                       col = \"red\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI have been working with the software Win ISI (used develop models for Foss NIR Systems) for a long time, and developing the PCA with a similar math treatment, we get the same Mahalanobis distance robust outliers than our calculation with the chemometric package.\n\n\nlet`s save the workspace for our next post\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws10.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_11/NIT_tutorial_11.html",
    "href": "posts/NIT_tutorial_11/NIT_tutorial_11.html",
    "title": "PCA - NIT tutorial (part 11)",
    "section": "",
    "text": "The first idea for this post is to add a new variable with the robust Mahalanobis distance value we have obtained in the previous post. From this variable, we create a new factor variable to define three types of samples: “no H outlier” for the samples with a robust mahalanobis distance lower than 3, “Warning H outlier” for the samples with values betweeen 3 and 4, and “Action H outlier” for the samples with values higher than 4..\nLet`s start by loading our workspace and the libraries we are going to use:\nAs we are going to work from now with the spectra math treated with scatter correction and second derivative, we can create a new dataframe with this spectra data, the reference values and other user defined fields that we can consider as the robust mahalanobis distance we have been talking before.\nNow let`s add the new variable with the robust mahalanobis distances. Normally, if the distances are below 3 the samples are not considered as outliers, if they are between 3 and 4 are considered as warning outliers and if they are over 4, they are considered as action outliers. it is important to know if the outliers have some relation with extreme reference values (for every parameter) or any other variables like the origin, temperature, instrument (in case we have more than one in our database), etc. Let´s add a new factor variable to define if the samples are “no ourliers”, “warning ourliers” or “action outliers”.\nbefore to develop the regressions, why not to see if the outliers are related to extreme samples for the different parameters. We can see that giving colors to the histograms to the histograms (for example). So let`s plot the histograms for the tecator parameters ( moisture, fat and protein)"
  },
  {
    "objectID": "posts/NIT_tutorial_11/NIT_tutorial_11.html#histograms-for-moisture-with-mahalanobis-ranges-colors.",
    "href": "posts/NIT_tutorial_11/NIT_tutorial_11.html#histograms-for-moisture-with-mahalanobis-ranges-colors.",
    "title": "PCA - NIT tutorial (part 11)",
    "section": "Histograms for moisture with Mahalanobis ranges colors.",
    "text": "Histograms for moisture with Mahalanobis ranges colors.\n\nggplot(tecator2, aes(x = Moisture, fill = outlier)) + \n  geom_histogram(position = \"identity\", alpha = 1, bins = 50) +\n  scale_fill_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))"
  },
  {
    "objectID": "posts/NIT_tutorial_11/NIT_tutorial_11.html#histograms-for-fat-with-mahalanobis-ranges-colors.",
    "href": "posts/NIT_tutorial_11/NIT_tutorial_11.html#histograms-for-fat-with-mahalanobis-ranges-colors.",
    "title": "PCA - NIT tutorial (part 11)",
    "section": "Histograms for fat with Mahalanobis ranges colors.",
    "text": "Histograms for fat with Mahalanobis ranges colors.\n\nggplot(tecator2, aes(x = Fat, fill = outlier)) +                 \n  geom_histogram(position = \"identity\", alpha = 1, bins = 50) +\n  scale_fill_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))"
  },
  {
    "objectID": "posts/NIT_tutorial_11/NIT_tutorial_11.html#histograms-for-protein-with-mahalanobis-ranges-colors.",
    "href": "posts/NIT_tutorial_11/NIT_tutorial_11.html#histograms-for-protein-with-mahalanobis-ranges-colors.",
    "title": "PCA - NIT tutorial (part 11)",
    "section": "Histograms for protein with Mahalanobis ranges colors.",
    "text": "Histograms for protein with Mahalanobis ranges colors.\n\nggplot(tecator2, aes(x = Protein, fill = outlier)) +\n  geom_histogram(position = \"identity\", alpha = 1, bins = 50) +\n  scale_fill_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))\n\n\n\n\nAs we can see extreme samples are normally warning or action outliers (we can confirm this better when we will develop the regressions on coming posts), but there are other causes as well.\nlet`s save the workspace for our next post\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws11.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_12/NIT_tutorial_12.html",
    "href": "posts/NIT_tutorial_12/NIT_tutorial_12.html",
    "title": "PCA - NIT tutorial (part 12)",
    "section": "",
    "text": "In a previous post (from this tutorial) we have seen the intercorrelation plots between parameters and we have seen some outliers (they did not follow the trend), but are those samples mahalanobis distance spectral outliers, for the math treatment used?. Now we can go back to that point and check it.\nLet`s start by loading our workspace and the libraries we are going to use:"
  },
  {
    "objectID": "posts/NIT_tutorial_12/NIT_tutorial_12.html#moisture-vs-fat",
    "href": "posts/NIT_tutorial_12/NIT_tutorial_12.html#moisture-vs-fat",
    "title": "PCA - NIT tutorial (part 12)",
    "section": "Moisture vs Fat",
    "text": "Moisture vs Fat\n\ntecator2 %>% \n  ggplot(aes( x = Moisture, y = Fat, color = outlier)) +\n  geom_point() + \n  geom_smooth(method = lm, size = 1) +\n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))\n\n\n\n\nIn this case we can see how the extreme samples (with high fat and low moisture are action or warning outliers), and that some of the high moisture - low fat outliers dis not follow the trend."
  },
  {
    "objectID": "posts/NIT_tutorial_12/NIT_tutorial_12.html#moisture-vs-protein",
    "href": "posts/NIT_tutorial_12/NIT_tutorial_12.html#moisture-vs-protein",
    "title": "PCA - NIT tutorial (part 12)",
    "section": "Moisture vs Protein",
    "text": "Moisture vs Protein\n\ntecator2 %>% \n  ggplot(aes( x = Moisture, y = Protein, color = outlier)) +\n  geom_point() + \n  geom_smooth(method = lm, size = 1) +\n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))\n\n\n\n\nin this case we do not see that almost all the low moisture - low protein are marked as outliers, but the rest of the outliers (except two warning) follow the trend."
  },
  {
    "objectID": "posts/NIT_tutorial_12/NIT_tutorial_12.html#fat-vs-protein",
    "href": "posts/NIT_tutorial_12/NIT_tutorial_12.html#fat-vs-protein",
    "title": "PCA - NIT tutorial (part 12)",
    "section": "Fat vs Protein",
    "text": "Fat vs Protein\n\ntecator2 %>% \n  ggplot(aes( x = Fat, y = Protein, color = outlier)) +\n  geom_point() + \n  geom_smooth(method = lm, size = 1) +\n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))\n\n\n\n\nit seems the same case than Protein vs Moisture."
  },
  {
    "objectID": "posts/NIT_tutorial_12/NIT_tutorial_12.html#relation-between-the-spectra-pattern-an-the-mahalanobis-distance-ranges",
    "href": "posts/NIT_tutorial_12/NIT_tutorial_12.html#relation-between-the-spectra-pattern-an-the-mahalanobis-distance-ranges",
    "title": "PCA - NIT tutorial (part 12)",
    "section": "Relation between the spectra pattern an the Mahalanobis distance ranges",
    "text": "Relation between the spectra pattern an the Mahalanobis distance ranges\nOther observation we can do is with the spectra math treated giving colors to the spectra math treated, and looking if we see some patterns: (First we have to do some work removing the prefix (snvdt2der2_spec.)to the wavelength headers).\n\ntecator3 <- bind_cols(tecator2$SampleID, tecator2$snvdt2der2_spec, tecator2$outlier) \ncolnames(tecator3) <- c(\"SampleID\", seq(850, 1048, 2), \"outlier\")\n\n\ntecator3  %>% \n  pivot_longer(cols = c(2:101),\n               names_to = \"wavelength\",\n               values_to = \"absorbance\")  %>%  \n  mutate(wavelength = as.integer(str_extract(wavelength, \"[:digit:]+\"))) %>% \n    ggplot(aes(x = wavelength, y = absorbance, group = SampleID, color = outlier)) + \n  geom_line(alpha = 0.5) + \n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\")) +\n  theme_light()\n\n\n\n\nIn the spectra we can see how the warning and action mahalanobis distance outliers are also extreme vs. the absorbance values. We have to take into account that these absorbances have a relationship with the concentration of the parameters: Fat, Moisture and Protein.\nNow we save the workspace to use in the next post.\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws12.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_13/NIT_tutorial_13.html",
    "href": "posts/NIT_tutorial_13/NIT_tutorial_13.html",
    "title": "PLS - NIT tutorial (part 13)",
    "section": "",
    "text": "In this post we are going to use the package Caret to develop PLS models for protein, fat and moisture, but first we have to split the data in two sets, one for training and other for testing. Now we load the libraries we need, and the workspace from the previous post.\n\nload(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws12.RData\")\nlibrary(tidymodels)\nlibrary(caret)\n\nWe did use Caret to split the tecator data in the post NIT_tutorial_5, so we repeat the process again with our last dataframe (from the previous post “tecator2”):\n\nset.seed(1234)\ntecator2_split_prot <- initial_split(tecator2, prop = 3/4, strata = Protein)\ntecator2_split_fat <- initial_split(tecator2, prop = 3/4, strata = Fat)\ntecator2_split_moi <- initial_split(tecator2, prop = 3/4, strata = Moisture)\n\ntec2_prot_train <- training(tecator2_split_prot)\ntec2_prot_test <- testing(tecator2_split_prot)\n\ntec2_fat_train <- training(tecator2_split_fat)\ntec2_fat_test <- testing(tecator2_split_fat)\n\ntec2_moi_train <- training(tecator2_split_moi)\ntec2_moi_test <- testing(tecator2_split_moi)\n\nWe have done this in a random way, so we expect that some of the mahalanobis distance outliers samples have gone to the training set and the remaining to the test set. Now, we can start to develop the regressions with the training set, and the validation with the test set, using the Caret package with the “pls” algorithm. We will use the cross validation (10 folds), to select the number of terms."
  },
  {
    "objectID": "posts/NIT_tutorial_13/NIT_tutorial_13.html#model-and-validation-performance-for-protein",
    "href": "posts/NIT_tutorial_13/NIT_tutorial_13.html#model-and-validation-performance-for-protein",
    "title": "PLS - NIT tutorial (part 13)",
    "section": "Model and validation performance for Protein",
    "text": "Model and validation performance for Protein\n\nset.seed(1234)\nctrl <- trainControl(method = \"cv\", number = 10)\ntec2_pls_model_prot <- train(y = tec2_prot_train$Protein,\n  x = tec2_prot_train$snvdt2der2_spec,\n  method = \"pls\",\n  trControl = ctrl)\n\n\ntec2_pls_model_prot\n\nPartial Least Squares \n\n160 samples\n100 predictors\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 144, 144, 144, 144, 144, 143, ... \nResampling results across tuning parameters:\n\n  ncomp  RMSE      Rsquared   MAE      \n  1      1.451693  0.7398494  1.0940694\n  2      1.342024  0.7854652  1.0083106\n  3      1.301409  0.8228018  0.9822213\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was ncomp = 3.\n\n\nnow we can see how the model performs with the test set, and create a table with the “SampleID\n\npls_preds <- predict(tec2_pls_model_prot, tec2_prot_test$snvdt2der2_spec)\ntest_prot_preds <- bind_cols(tec2_prot_test$SampleID ,tec2_prot_test$Protein, pls_preds, tec2_prot_test$outlier)\ncolnames(test_prot_preds) <- c(\"SampleID\", \"Prot_lab\", \"Prot_pred\", \"Outlier\")\n\nan XY plot (laboratory vs. predicted values) can gives an idea of the performance of the validation test:\n\ntest_prot_preds %>% \n  ggplot(aes(x = Prot_lab, y = Prot_pred, colour = Outlier)) +\n  geom_point(size = 3) +\n  geom_abline() +\n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))\n\n\n\n\nFigure 1: Protein predicted vs reference values."
  },
  {
    "objectID": "posts/NIT_tutorial_13/NIT_tutorial_13.html#model-and-validation-performance-for-fat",
    "href": "posts/NIT_tutorial_13/NIT_tutorial_13.html#model-and-validation-performance-for-fat",
    "title": "PLS - NIT tutorial (part 13)",
    "section": "Model and validation performance for Fat",
    "text": "Model and validation performance for Fat\n\nset.seed(1234)\nctrl <- trainControl(method = \"cv\", number = 10)\ntec2_pls_model_fat <- train(y = tec2_fat_train$Fat,\n  x = tec2_fat_train$snvdt2der2_spec,\n  method = \"pls\",\n  trControl = ctrl)\n\n\ntec2_pls_model_fat\n\nPartial Least Squares \n\n160 samples\n100 predictors\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 144, 145, 143, 144, 144, 144, ... \nResampling results across tuning parameters:\n\n  ncomp  RMSE      Rsquared   MAE     \n  1      2.339072  0.9731581  1.832527\n  2      2.276391  0.9762236  1.757150\n  3      2.215674  0.9782784  1.744476\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was ncomp = 3.\n\n\nnow we can see how the model performs with the test set, and create a table with the “SampleID\n\npls_preds_fat <- predict(tec2_pls_model_fat, tec2_fat_test$snvdt2der2_spec)\ntest_fat_preds <- bind_cols(tec2_fat_test$SampleID ,tec2_fat_test$Fat, pls_preds_fat, tec2_fat_test$outlier)\ncolnames(test_fat_preds) <- c(\"SampleID\", \"Fat_lab\", \"Fat_pred\", \"Outlier\")\n\n\ntest_fat_preds %>% \n  ggplot(aes(x = Fat_lab, y = Fat_pred, colour = Outlier)) +\n  geom_point(size = 3) +\n  geom_abline() +\n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))"
  },
  {
    "objectID": "posts/NIT_tutorial_13/NIT_tutorial_13.html#model-and-validation-performance-for-moisture",
    "href": "posts/NIT_tutorial_13/NIT_tutorial_13.html#model-and-validation-performance-for-moisture",
    "title": "PLS - NIT tutorial (part 13)",
    "section": "Model and validation performance for Moisture",
    "text": "Model and validation performance for Moisture\n\nset.seed(1234)\nctrl <- trainControl(method = \"cv\", number = 10)\ntec2_pls_model_moi <- train(y = tec2_fat_train$Moisture,\n  x = tec2_fat_train$snvdt2der2_spec,\n  method = \"pls\",\n  trControl = ctrl)\n\n\ntec2_pls_model_moi\n\nPartial Least Squares \n\n160 samples\n100 predictors\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 144, 144, 143, 144, 144, 144, ... \nResampling results across tuning parameters:\n\n  ncomp  RMSE      Rsquared   MAE     \n  1      2.080841  0.9583109  1.641792\n  2      2.031741  0.9600832  1.593240\n  3      2.014572  0.9612094  1.566407\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was ncomp = 3.\n\n\nnow we can see how the model performs with the test set, and create a table with the “SampleID\n\npls_preds_moi <- predict(tec2_pls_model_moi, tec2_moi_test$snvdt2der2_spec)\ntest_moi_preds <- bind_cols(tec2_moi_test$SampleID ,tec2_moi_test$Moisture, pls_preds_moi, tec2_moi_test$outlier)\ncolnames(test_moi_preds) <- c(\"SampleID\", \"Moi_lab\", \"Moi_pred\", \"Outlier\")\n\n\ntest_moi_preds %>% \n  ggplot(aes(x = Moi_lab, y = Moi_pred, colour = Outlier)) +\n  geom_point(size = 3) +\n  geom_abline() +\n  scale_color_manual(values = c(\"no outlier\" = \"green\",\n                                \"Warning outlier\" = \"orange\",\n                                \"Action outlier\" =\"red\"))\n\n\n\n\nNow I save the workspace to continue in the next post\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws13.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_13/NIT_tutorial_13.html#table-of-results",
    "href": "posts/NIT_tutorial_13/NIT_tutorial_13.html#table-of-results",
    "title": "PLS - NIT tutorial (part 13)",
    "section": "Table of results",
    "text": "Table of results\n\n\n\n\n\n\n\n\n\n\n\nParameter\nN training\nN test\nTerms\nC.V. error (SECV)\nTest Pred. error (SEV)\n\n\n\n\nProtein\n160\n55\n3\n1.30\n1.49\n\n\nFat\n160\n55\n3\n2.22\n2.34\n\n\nMoisture\n160\n56\n3\n2.01\n2.25"
  },
  {
    "objectID": "posts/NIT_tutorial_13/NIT_tutorial_13.html#conclussions",
    "href": "posts/NIT_tutorial_13/NIT_tutorial_13.html#conclussions",
    "title": "PLS - NIT tutorial (part 13)",
    "section": "Conclussions",
    "text": "Conclussions\nWith all the plots above we can ask ourselves several questions in order to find the better performance we can get from the data.\n\nCan we force the model to use more terms , (few for the complexity of the data) , does this option improves the results on the test set?\nCan we use another model algorithm (different to “pls”) to improve the results?.\n\ndo we have enough samples for those algorithms?\n\nDoes the “non MD outliers” samples predict better than the “warning” or “action” MD outliers?\nDo we see non linearities in the plots?\n\nHow we can manages these non linearities?\nMaybe adding more terms to the PLS model we improve the linearity.\n\nComment any other conclusions you have."
  },
  {
    "objectID": "posts/NIT_tutorial_2/NIT_tutorial_2.html",
    "href": "posts/NIT_tutorial_2/NIT_tutorial_2.html",
    "title": "Near Infrared Transmitance Tutorial (part 2)",
    "section": "",
    "text": "First we load the libraries we are going to use, and the “workspace” from the previous post:\n\nlibrary(tidyverse)\nlibrary(modeldata)\nload(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws1.RData\")\nls()\n\n[1] \"absorp\"    \"endpoints\" \"tecator\"  \n\n\nNow we can create another field called “SampleID” as a sequence from 1 to 215 (number of samples), it will be very usefull whenever we use the tecator dataframe:\n\ntecator <- tecator %>%   \n  rowid_to_column(var = \"SampleID\") \n\nThe tecator data is available as well in the library “modeldata”, but with the name “meats”, so we can load it into the workspace and work with it using the tidyverse and tidymodels libraries. The idea of this tutorial is getting use to work with tidyverse and tidymodels at the same time that with classic R.\n\ndata(meats)\n\nThe first 100 columns are the wavelengths are the datapoints and the last 3 the parameters, so we can rename de column names, and add an extra column called “SampleID” (same as row number).\n\ncolnames(meats) <- c(seq(850, 1048, by = 2), \"Moisture\", \"Fat\", \"Protein\")\n\nmeats <- \n  meats  %>% \n  rowid_to_column(var = \"SampleID\")"
  },
  {
    "objectID": "posts/NIT_tutorial_2/NIT_tutorial_2.html#histograms-with-ggplot",
    "href": "posts/NIT_tutorial_2/NIT_tutorial_2.html#histograms-with-ggplot",
    "title": "Near Infrared Transmitance Tutorial (part 2)",
    "section": "Histograms with ggplot",
    "text": "Histograms with ggplot\nNow we can see the histograms with ggplot\n\nmeats %>% \n  ggplot(aes(Protein)) +\n  geom_histogram(bins = 20) +\n  ggtitle(\"Protein Meat histogram\")\n\n\n\n\nFigure 1: Protein histogram.\n\n\n\n\nWe can do the same for moisture and fat, but with some code we can see all the histograms at the same time:\n\nmeats %>% \n  select(SampleID, Moisture, Fat, Protein) %>% \n  pivot_longer(cols = Moisture:Protein,\n               names_to = \"Parameter\",\n               values_to = \"Value\") %>% \n  mutate(Parameter = as.factor(Parameter)) %>% \n  ggplot(aes(Value)) +\n  geom_histogram() +\n  facet_wrap(~ Parameter, scales = \"free_x\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 2: Parameters histograms."
  },
  {
    "objectID": "posts/NIT_tutorial_2/NIT_tutorial_2.html#lets-see-the-raw-spectra-with-ggplot",
    "href": "posts/NIT_tutorial_2/NIT_tutorial_2.html#lets-see-the-raw-spectra-with-ggplot",
    "title": "Near Infrared Transmitance Tutorial (part 2)",
    "section": "Let´s see the raw spectra with ggplot",
    "text": "Let´s see the raw spectra with ggplot\nIn order to see the spectra with ggplot we pivot longer meats data grouping by SampleID:\n\nmeats_longer <- \n  meats  %>% \n  pivot_longer(cols = c(2:101),\n               names_to = \"wavelength\",\n               values_to = \"absorbance\")  %>%  \n  mutate(wavelength = as.integer(str_extract(wavelength, \"[:digit:]+\")))\n\nSave the workspace for future use\n\nmeats_longer  %>% \n  ggplot(aes(x = wavelength, y = absorbance, group = SampleID)) + \n  geom_line(alpha = 0.5) + \n  theme_light()\n\n\n\n\nFigure 3: Raw spectra with ggplot.\n\n\n\n\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws2.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_3/NIT_tutorial_3.html",
    "href": "posts/NIT_tutorial_3/NIT_tutorial_3.html",
    "title": "Near Infrared Transmitance Tutorial (part 3)",
    "section": "",
    "text": "Let´s start loading the libraries we are going to use in this post and the workspace from the previous post.\n\nlibrary(tidyverse)\nlibrary(corrplot)\nload(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws2.RData\")\nls()\n\n[1] \"absorp\"       \"endpoints\"    \"meats\"        \"meats_longer\" \"tecator\""
  },
  {
    "objectID": "posts/NIT_tutorial_3/NIT_tutorial_3.html#correlation-between-the-parameters-outcomes",
    "href": "posts/NIT_tutorial_3/NIT_tutorial_3.html#correlation-between-the-parameters-outcomes",
    "title": "Near Infrared Transmitance Tutorial (part 3)",
    "section": "Correlation between the parameters (outcomes)",
    "text": "Correlation between the parameters (outcomes)\nIt is important to check the correlation between the outcomes variables (Moisture, Fat and Protein in this case). As we remember the outcomes are in the “endpoints” matrix.\n\nendpoints %>% \n  cor()\n\n           Moisture        Fat    Protein\nMoisture  1.0000000 -0.9881002  0.8145212\nFat      -0.9881002  1.0000000 -0.8608965\nProtein   0.8145212 -0.8608965  1.0000000\n\n\nThe correlation matrix show how the are high correlations between the three parameters, but we can use graphics to see it more clearly:\n\ncorrplot(cor(endpoints), method = \"ellipse\")\n\n\n\n\nFigure 1: Inter-correlation between parameters.\n\n\n\n\nBut to check better the trends and the possible outliers, we can use the function “pairs\n\npairs(endpoints)\n\n\n\n\nFigure 2: Parameters inter-correlation\n\n\n\n\nThis way we can see at least six outliers that seems to have some bias versus the linear trend. What are the reason for these outliers? (samples different from the rest, different reference method, bias in the reference method,…). We will try to see along the tutorial."
  },
  {
    "objectID": "posts/NIT_tutorial_3/NIT_tutorial_3.html#correlation-between-the-wavelengths-predictors",
    "href": "posts/NIT_tutorial_3/NIT_tutorial_3.html#correlation-between-the-wavelengths-predictors",
    "title": "Near Infrared Transmitance Tutorial (part 3)",
    "section": "Correlation between the wavelengths (predictors)",
    "text": "Correlation between the wavelengths (predictors)\nIt is known that the NIR or NIT predictor variables are highly correlated, due that we are working with overtones and combination bands, so the correlation matrix in this case show high correlation between all the variables, due to we are in the third overtone and working with very broad bands.For this reason we have to apply math treatments to the spectra to remove the scatter effect and derivatives to improve the resolution of the bands. The correlation between predictors is a long matrix (100.100), so the best way to see it it is graphically. By now we see the correlation matrix of the raw spectra (without any math treatment)\n\ncorrplot(cor(absorp), method = \"circle\", type = \"upper\", tl.cex = 0.5)\n\n\n\n\nFigure 3: Spectra collinearity."
  },
  {
    "objectID": "posts/NIT_tutorial_3/NIT_tutorial_3.html#correlation-between-outcomes-and-predictors",
    "href": "posts/NIT_tutorial_3/NIT_tutorial_3.html#correlation-between-outcomes-and-predictors",
    "title": "Near Infrared Transmitance Tutorial (part 3)",
    "section": "Correlation between outcomes and predictors",
    "text": "Correlation between outcomes and predictors\nAnother point is how the variation in the predictors matrix correlates with the variation of the outcomes. What we do is to see which wavelengths correlate better with a certain parameter getting three correlation spectra (one for every parameter).\n\ncor_rawspec_moi <- cor(tecator$Moisture, tecator$spec)\ncor_rawspec_fat <- cor(tecator$Fat, tecator$spec)\ncor_rawspec_prot <- cor(tecator$Protein, tecator$spec)\n\ncor_rawspec <- as.data.frame(rbind(cor_rawspec_moi, cor_rawspec_fat, cor_rawspec_prot))\ncor_rawspec <- cor_rawspec %>% \n  mutate(Parameter = as.factor(c(\"Moisture\", \"Fat\", \"Protein\")))\n\ncor_rawspec %>% \n  pivot_longer(cols = c(1:100), names_to = \"Wavelength\", values_to = \"Correlation\") %>% \n  mutate(Wavelength = as.integer(Wavelength)) %>% \n  ggplot(aes(x = Wavelength, y = Correlation, group = Parameter, col = Parameter)) +\n  geom_line()\n\n\n\n\nFigure 4: Correlation absorbance vs. parameters.\n\n\n\n\nAs we can see there are no wavelengths with high correlations, and if we would auto-scale every correlation spectrum, the spectrum would seem as a meat sample spectra (for moisture and protein inverted). All this is due to the scatter physical effects. So, with some math treatments to remove it the correlation will improve. Anyway, in the third overtone due to the bands overlapping, we would need a multivariate calibration with all or almost all the wavelengths.\nAs always save the workspace for future use:\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws3.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_4/NIT_tutorial_4.html",
    "href": "posts/NIT_tutorial_4/NIT_tutorial_4.html",
    "title": "Near Infrared Transmitance Tutorial (part 4)",
    "section": "",
    "text": "Let´s see what we have in the workspace from the previous posts:\n\nload(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws3.RData\")\nls()\n\n[1] \"absorp\"           \"cor_rawspec\"      \"cor_rawspec_fat\"  \"cor_rawspec_moi\" \n[5] \"cor_rawspec_prot\" \"endpoints\"        \"meats\"            \"meats_longer\"    \n[9] \"tecator\"         \n\n\nWe can remove some objects we don´t need\n\nrm(\"cor_rawspec_fat\", \"cor_rawspec_moi\", \"cor_rawspec_prot\")\n\nNow we load the libraries we will use:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/NIT_tutorial_4/NIT_tutorial_4.html#scatter-correction-math-treatments",
    "href": "posts/NIT_tutorial_4/NIT_tutorial_4.html#scatter-correction-math-treatments",
    "title": "Near Infrared Transmitance Tutorial (part 4)",
    "section": "Scatter correction math-treatments",
    "text": "Scatter correction math-treatments\nThe idea now is to apply some math treatments to the raw spectra and check which one improves the correlation with the parameters of interest. Normally there are some common scatter removal algorithms that I use:\n\nStandard Normal Variate (SNV)\nDetrend (linear or quadratic)\nSNV + Detrend (linear or quadratic)\nMultiple Scatter Correction\n\nThere are some packages in R which have these math treatment with this name or a similar one, or we can create functions to apply these algorithms to the spectra matrix."
  },
  {
    "objectID": "posts/NIT_tutorial_4/NIT_tutorial_4.html#standard-normal-variate-snv",
    "href": "posts/NIT_tutorial_4/NIT_tutorial_4.html#standard-normal-variate-snv",
    "title": "Near Infrared Transmitance Tutorial (part 4)",
    "section": "Standard Normal Variate (SNV)",
    "text": "Standard Normal Variate (SNV)\nLet´s start using SNV, where we center every spectrum (subtracting the mean) and scale it (dividing by the standard deviation):\n\n#The algorithm is applied to the columns, so we transpose the matrix\nabsorp_snv <- scale(t(absorp), center = TRUE, scale = TRUE)\n#Let´s convert the corrected matrix as usual\nabsorp_snv <- t(absorp_snv)\n\nmatplot(colnames(absorp_snv), t(absorp_snv), type = \"l\", xlab = \"Wavelength (nm)\", ylab = \"Absorbance\", main = \"SNV Meat Spectra\")\n\n\n\n\nFigure 1: Meat spectra treated with SNV.\n\n\n\n\nWe can add the matrix treated with the SNV math treatment to the tecator dataframe\n\ntecator$snv_spec <- absorp_snv"
  },
  {
    "objectID": "posts/NIT_tutorial_4/NIT_tutorial_4.html#correlation-between-outcomes-and-predictors-with-snv",
    "href": "posts/NIT_tutorial_4/NIT_tutorial_4.html#correlation-between-outcomes-and-predictors-with-snv",
    "title": "Near Infrared Transmitance Tutorial (part 4)",
    "section": "Correlation between outcomes and predictors (with SNV)",
    "text": "Correlation between outcomes and predictors (with SNV)\nNow we can see if the correlation is improved\n\ncor_snvspec_moi <- cor(tecator$Moisture, tecator$snv_spec)\ncor_snvspec_fat <- cor(tecator$Fat, tecator$snv_spec)\ncor_snvspec_prot <- cor(tecator$Protein, tecator$snv_spec)\n\ncor_snvspec <- as.data.frame(rbind(cor_snvspec_moi, cor_snvspec_fat, cor_snvspec_prot))\n\ncor_snvspec <- cor_snvspec %>% \n  mutate(Parameter = as.factor(c(\"Moisture\", \"Fat\", \"Protein\")))\n\ncor_snvspec %>% \n  pivot_longer(cols = c(1:100), names_to = \"Wavelength\", values_to = \"Correlation\") %>% \n  mutate(Wavelength = as.integer(Wavelength)) %>% \n  ggplot(aes(x = Wavelength, y = Correlation, group = Parameter, col = Parameter)) +\n  geom_line()\n\n\n\n\nFigure 2: Correlation SNV signal with the parametes.\n\n\n\n\nNow, apart from the better correlation we can see an improvement in the definition of the correlations (positives and negatives), and the correlation spectra confirm what we have seen in the correlation between the parameters.\nAs always save the workspace for future use:\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws4.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_5/NIT_tutorial_5.html",
    "href": "posts/NIT_tutorial_5/NIT_tutorial_5.html",
    "title": "Near Infrared Transmitance Tutorial (part 5)",
    "section": "",
    "text": "As always load the previous workspace:\n\nload(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws4.RData\")\nls()\n\n [1] \"absorp\"           \"absorp_snv\"       \"cor_rawspec\"      \"cor_snvspec\"     \n [5] \"cor_snvspec_fat\"  \"cor_snvspec_moi\"  \"cor_snvspec_prot\" \"endpoints\"       \n [9] \"meats\"            \"meats_longer\"     \"tecator\"         \n\n\nWe need in this post these libraries\n\nlibrary(pls)\nlibrary(tidymodels)"
  },
  {
    "objectID": "posts/NIT_tutorial_5/NIT_tutorial_5.html#multiple-scatter-correction-msc",
    "href": "posts/NIT_tutorial_5/NIT_tutorial_5.html#multiple-scatter-correction-msc",
    "title": "Near Infrared Transmitance Tutorial (part 5)",
    "section": "Multiple Scatter Correction (MSC)",
    "text": "Multiple Scatter Correction (MSC)\nWe use the function msc from the pls package\n\nabsorp_msc <- msc(absorp)\n\nThis is a very simple step, and we can see the result and compare it with SNV.\n\npar(mfrow=c(1, 2))\nmatplot(colnames(absorp_msc), t(absorp_msc), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"MSC spectra\")\nmatplot(colnames(absorp_snv), t(absorp_snv), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNV spectra\")\n\n\n\n\nFigure 1: MSC vs. SNV\n\n\n\n\nas we can see they are quite similar if we don´t take into account that the SNV is centered. SNV and MSC have very different calculations:\n\nSNV use independently every spectrum calculating the mean and the standard deviation of the spectrum data points and use them in the calculation.\nMSC calculate the mean spectrum and use it to calculate the slope (b) and intercept (a) with a linear regression to every particular spectrum, and after that use “a” and “b” to correct that particular spectrum. A new a and b are calculated for the next spectrum using again the mean spectrum and the new spectrum in the regression."
  },
  {
    "objectID": "posts/NIT_tutorial_5/NIT_tutorial_5.html#split-data-into-training-a-validation",
    "href": "posts/NIT_tutorial_5/NIT_tutorial_5.html#split-data-into-training-a-validation",
    "title": "Near Infrared Transmitance Tutorial (part 5)",
    "section": "Split data into training a validation",
    "text": "Split data into training a validation\nThis point is a good occasion to split the data into a training ans a test set. There are several ways to do it, but let´s use tidymodels this time:\n\nset.seed(1234)\ntecator_split <- initial_split(tecator, prop = 3/4, strata = Protein)\n\nWe have selected as strata the parameter protein, because it is the first model that we will develop.\n\ntec_prot_train <- training(tecator_split)\ntec_prot_test <- testing(tecator_split)\n\nNow we have two sets (training and test), and we will continue working with the training set, hiding the test set until we use it for the final validation. But before to hide the test set we will use it this time to explain the process to apply math treatments to the test set. Let´s apply the MSC math treatment again, but this time only to the training set:\n\ntec_prot_train_msc <- msc(tec_prot_train$spec)"
  },
  {
    "objectID": "posts/NIT_tutorial_5/NIT_tutorial_5.html#apply-msc-to-the-test-set",
    "href": "posts/NIT_tutorial_5/NIT_tutorial_5.html#apply-msc-to-the-test-set",
    "title": "Near Infrared Transmitance Tutorial (part 5)",
    "section": "Apply MSC to the test set",
    "text": "Apply MSC to the test set\nThe mean train spectrum is keep as reference, and now we can apply the MSC to the test set:\n\ntec_prot_test_msc <- predict(tec_prot_train_msc, newdata = tec_prot_test$spec)\n\nLet´s compare the two sets:\n\npar(mfrow=c(1, 2))\nmatplot(colnames(tec_prot_train_msc), t(tec_prot_train_msc), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"MSC training set\", col = \"blue\")\nmatplot(colnames(tec_prot_test_msc), t(tec_prot_test_msc), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"MSC test set\", col = \"green\")\n\n\n\n\nFigure 2: Training and Test sets math treated with MSC\n\n\n\n\nNow we can save these values in their respective dataframes:\n\ntec_prot_train$msc_spec <- tec_prot_train_msc\ntec_prot_test$msc_spec <- tec_prot_test_msc\n\nand save the workspace:\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws5.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_6/NIR_tutotial_6.html",
    "href": "posts/NIT_tutorial_6/NIR_tutotial_6.html",
    "title": "Near Infrared Transmitance Tutorial (part 6)",
    "section": "",
    "text": "First we load the work we have done until now:\n\nload(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws5.RData\")\nls()\n\n [1] \"absorp\"             \"absorp_msc\"         \"absorp_snv\"        \n [4] \"cor_rawspec\"        \"cor_snvspec\"        \"cor_snvspec_fat\"   \n [7] \"cor_snvspec_moi\"    \"cor_snvspec_prot\"   \"endpoints\"         \n[10] \"meats\"              \"meats_longer\"       \"tec_prot_test\"     \n[13] \"tec_prot_test_msc\"  \"tec_prot_train\"     \"tec_prot_train_msc\"\n[16] \"tecator\"            \"tecator_split\"     \n\n\nWe can remove some files we have use for some visualization: it is important to maintain the dataframes we will use for the model development with different math treatments and the raw spectra.\n\nrm(cor_rawspec_fat,cor_rawspec_moi, cor_rawspec_prot,\n   cor_snvspec_fat, cor_snvspec_moi, cor_snvspec_prot)\n\nResuming what we have in th tecator dataframe:\n\nnames(tecator)\n\n[1] \"SampleID\" \"Moisture\" \"Fat\"      \"Protein\"  \"spec\"     \"snv_spec\"\n\n\nAs we can see we have the Sample ID, the parameters with the laboratory values for moisture, fat and protein, and the spectra without treatment (raw) and with the SNV treatment. At the moment we take apart the MSC math treatment , we have calculated in the previous post, and keep it for future use."
  },
  {
    "objectID": "posts/NIT_tutorial_6/NIR_tutotial_6.html#detrend-math-treatment",
    "href": "posts/NIT_tutorial_6/NIR_tutotial_6.html#detrend-math-treatment",
    "title": "Near Infrared Transmitance Tutorial (part 6)",
    "section": "DETREND math treatment",
    "text": "DETREND math treatment\nWith the detrend we want to remove the linear trend caused normally by the scatter. This shift is no so obvious in the wavelength range we are using in this tutorial, but when using NIR spectra range (1100 - 2500 nm) the shift increase quite a lot and can be linear or quadratic depending on the type of sample or sample presentation. Detrend normally is combined with SNV, and this combination is in the list of some of the commercial software available for NIR or NIT instruments. The math treatments we can see in this post are:\n\nDetrend linear only\nSNV and linear detrend\nSNV and quadratic detrend"
  },
  {
    "objectID": "posts/NIT_tutorial_6/NIR_tutotial_6.html#detrend-only-linear",
    "href": "posts/NIT_tutorial_6/NIR_tutotial_6.html#detrend-only-linear",
    "title": "Near Infrared Transmitance Tutorial (part 6)",
    "section": "Detrend only (linear)",
    "text": "Detrend only (linear)\nWe will use the {pracma} library and the function “detrend”.\n\nlibrary(pracma)\n\nLet´s apply the function to the raw spectra, and see the result:\n\ndt_spec <- pracma::detrend(tecator$spec)\npar(mfrow=c(1, 2))\nmatplot(colnames(tecator$spec), t(tecator$spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"Raw spectra\", col = \"grey\")\nmatplot(colnames(dt_spec), t(dt_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"Only linear detrend\", col = \"blue\")\n\n\n\n\nFigure 1: Raw vs. Detrend only spectra\n\n\n\n\nin the figure we compare the spectra without any treatment (left) with the spectra with the linear detrend, and we can see how the spectra become flatter due to the trend removal, but the result can be improved with some normalization to remove the baseline shift, so for that reason we use the detrend and SNV combined."
  },
  {
    "objectID": "posts/NIT_tutorial_6/NIR_tutotial_6.html#snv-and-linear-detrend",
    "href": "posts/NIT_tutorial_6/NIR_tutotial_6.html#snv-and-linear-detrend",
    "title": "Near Infrared Transmitance Tutorial (part 6)",
    "section": "SNV and linear detrend",
    "text": "SNV and linear detrend\nIn this case we will use another library {prospectr} , using p = 1 to remove the linear trend.\n\nlibrary(prospectr)\nsnvdt1_spec <- prospectr::detrend(tecator$spec, \n                                  wav = as.numeric(colnames(tecator$spec)),\n                                  p = 1) \n\nNow we can compare the result with the raw spectra\n\npar(mfrow=c(1, 2))\nmatplot(colnames(tecator$spec), t(tecator$spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"Raw spectra\", col = \"grey\")\nmatplot(colnames(snvdt1_spec), t(snvdt1_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNV and Linear Detrend\", col = \"blue\")\n\n\n\n\nFigure 2: Raw vs. SNV+DT1\n\n\n\n\nAs we can see there is an improvement in the result. We can see if the change from p = 1 to p = 2 make some differences:"
  },
  {
    "objectID": "posts/NIT_tutorial_6/NIR_tutotial_6.html#snv-and-quadratic-detrend",
    "href": "posts/NIT_tutorial_6/NIR_tutotial_6.html#snv-and-quadratic-detrend",
    "title": "Near Infrared Transmitance Tutorial (part 6)",
    "section": "SNV and quadratic detrend",
    "text": "SNV and quadratic detrend\n\nsnvdt2_spec <- prospectr::detrend(tecator$spec, \n                                  wav = as.numeric(colnames(tecator$spec)),\n                                  p = 2) \n\nNow we can compare the result with the raw spectra and linear detrend spectra.\n\npar(mfrow=c(1, 3))\nmatplot(colnames(tecator$spec), t(tecator$spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"Raw spectra\", col = \"grey\")\nmatplot(colnames(snvdt1_spec), t(snvdt1_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNV and Linear Detrend\", col = \"blue\")\nmatplot(colnames(snvdt2_spec), t(snvdt2_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNV and Quadratic Detrend\", col = \"blue\")\n\n\n\n\nFigure 3: Raw vs. SNV+DT1 and SNV+DT2"
  },
  {
    "objectID": "posts/NIT_tutorial_6/NIR_tutotial_6.html#detrend-correlations-with-protein-depending-on-type",
    "href": "posts/NIT_tutorial_6/NIR_tutotial_6.html#detrend-correlations-with-protein-depending-on-type",
    "title": "Near Infrared Transmitance Tutorial (part 6)",
    "section": "Detrend correlations with Protein depending on type",
    "text": "Detrend correlations with Protein depending on type\nLet´s check the correlations for the different math treatment combinations using detrend to get some conclusions.\n\ncor_prot_dt <- cor(tecator$Protein, dt_spec)\ncor_prot_snvdt1 <- cor(tecator$Protein, snvdt1_spec)\ncor_prot_snvdt2 <- cor(tecator$Protein, snvdt2_spec)\n\ncor_prot_with_dt <- as.data.frame(rbind(cor_prot_dt, cor_prot_snvdt1, cor_prot_snvdt2))\n\nlibrary(tidyverse)\n\ncor_prot_with_dt <- cor_prot_with_dt %>% \n  mutate(Mat_treatment = as.factor(c(\"DT\", \"SNV+DT1\", \"SNV+DT2\")))\n\n\ncor_prot_with_dt %>% \n  pivot_longer(cols = c(1:100), names_to = \"Wavelength\", values_to = \"Correlation\") %>% \n  mutate(Wavelength = as.integer(Wavelength)) %>% \n  ggplot(aes(x = Wavelength, y = Correlation, group = Mat_treatment, col = Mat_treatment)) +\n  geom_line()\n\n\n\n\nFigure 4: Wavelength correlation with protein for the different Detrend treatments\n\n\n\n\nAs we can see it seems that there are an improvement in the correlation when using Quadratic Detrend combined with SNV. Anyway we wiil see during the models developments if the statistics confirm this.\nWe can add all these three new math-treatments to the tecator dataframe for future use:\n\ntecator$dt_spec <- dt_spec\ntecator$snvdt1_spec <- snvdt1_spec\ntecator$sndt2_spec <- snvdt2_spec\n\nLet´s save the workspace\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws6.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_7/NIT_tutorial_7.html",
    "href": "posts/NIT_tutorial_7/NIT_tutorial_7.html",
    "title": "Near Infrared Transmitance Tutorial (part 7)",
    "section": "",
    "text": "Let´s start by loading our workspace and the libraries we will use in this post:\nWe have seen some of the most popular scatter correction methods in the previous posts, and now, in this one, we will try the derivatives (first and second) alone and combined with SNV and the quadratic detrend."
  },
  {
    "objectID": "posts/NIT_tutorial_7/NIT_tutorial_7.html#first-derivative",
    "href": "posts/NIT_tutorial_7/NIT_tutorial_7.html#first-derivative",
    "title": "Near Infrared Transmitance Tutorial (part 7)",
    "section": "First Derivative",
    "text": "First Derivative\nWe are use to see peaks and try to see at which wavelengths are the peaks and find out what type of bonds absorb at those wavelengths. Of course in the NIR bands, due to they are quite broad bands, the peaks are not so sharp as we would like to see them (like in the middle infrared), and everything became even worse as they combine with other neighbors bands forming overlapping bands even broader.\nThe derivatives improve the resolution, increasing the separation of the overlaping bands, but the cost is the difficulty to interpret them. In the case of the first derivative, the peak maximum change to a zero-crossing. Let´s use the {prospectr} package to calculate the first derivative of the meat raw spectra: The fuction we use is gapDer, where:\n\nX = the raw spectra matrix (we could use absorp or tecator$spec)\nm = order of the derivative (for the first derivative we use 1)\nw = gap size (we will use 1)\ns = segment size (space on both sides of the gap to average the absorbance values)\ndelta.wav = interval between data points (2 in this case)\n\nLet´s calculate the first derivative alone and the combination of SNV and Detrend plus the first derivative:\n\n#First derivative calculation\nder1_spec <- gapDer(absorp, m = 1, w = 5, s = 1, delta.wav = 2)\n#SNV and Detrend2 plus First Derivative\nsnvdt2der1_spec <- gapDer(tecator$sndt2_spec, m = 1, w = 5, s = 1, delta.wav = 2)\n\n\n\n\nFigure 1 compares the spectra treated with SNV plus Quadratic Detrend with the spectra of just the first derivative.\n\nmatplot(colnames(tecator$sndt2_spec), t(tecator$sndt2_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNVDT2 vs 1º Der\", col = \"black\", xaxt = \"n\")\npar(new=TRUE)\nmatplot(colnames(der1_spec), t(der1_spec), type = \"l\",lty = 4,axes = FALSE, xlab = \" \", ylab = \" \", main = \" \", col = \"red\", bty = \"n\")\naxis(4)\naxis(1)\n\n\n\n\nFigure 1: SNVDT2 and First derivative compared\n\n\n\n\nFigure 2 compares the spectra treated with SNV plus Quadratic Detrend with the first derivative applied to the SNV+DT2 spectra.\n\nmatplot(colnames(tecator$sndt2_spec), t(tecator$sndt2_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNVDT2 vs SNVDT2 + 1º Der\", col = \"black\", xaxt = \"n\")\npar(new=TRUE)\nmatplot(colnames(snvdt2der1_spec), t(snvdt2der1_spec), type = \"l\",lty = 4,axes = FALSE, xlab = \" \", ylab = \" \", main = \" \", col = \"red\", bty = \"n\")\naxis(4)\naxis(1)\n\n\n\n\nFigure 2: SNVDT2 and SNVDT2 + First Derivative compared"
  },
  {
    "objectID": "posts/NIT_tutorial_7/NIT_tutorial_7.html#second-derivative",
    "href": "posts/NIT_tutorial_7/NIT_tutorial_7.html#second-derivative",
    "title": "Near Infrared Transmitance Tutorial (part 7)",
    "section": "Second derivative",
    "text": "Second derivative\nIn the calculation of the second derivative the peak maximum becomes a peak minimum, creating some kind of shoulders on the sides so it is necessary to have this on mind when interpreting the spectra. The resolution of the bands change depending of the values of “w” and “s” we choose, if the values are lower the resolution increase and at the same time the noise, so it is necessary to find a compromise between this both elements.\nNow let´s calculate the second derivative for the raw spectra and for the spectra treated with SNV+DT2 ( we have done this calculation in the previous post).\n\nder2_spec <- gapDer(absorp, m = 2, w = 5, s = 1, delta.wav = 2)\nsnvdt2der2_spec <- gapDer(tecator$sndt2_spec, m = 2, w = 5, s = 1, delta.wav = 2)\n\nWe have to prepare some code to match the wavelengths due that the derivatives reduce the wavelenth range on both extremes depending of the values of “w” and “s”.\n\n\n\nFigure 3 compares the spectra treated with SNV plus Quadratic Detrend with the spectra of just the second derivative.\n\nmatplot(colnames(tecator$sndt2_spec), t(tecator$sndt2_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNVDT2 vs 2º Der\", col = \"black\", xaxt = \"n\")\npar(new=TRUE)\nmatplot(colnames(der2_spec), t(der2_spec), type = \"l\",lty = 4, axes = FALSE, xlab = \" \", ylab = \" \", main = \" \", col = \"red\", bty = \"n\")\naxis(4)\naxis(1)\n\n\n\n\nFigure 3: SNVDT2 and Second derivative compared\n\n\n\n\nFigure 4 compares the spectra treated with SNV plus Quadratic Detrend with the second derivative applied to the SNV+DT2 spectra.\n\nmatplot(colnames(tecator$sndt2_spec), t(tecator$sndt2_spec), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \"SNVDT2 vs SNVDT2 + 2º Der\", col = \"black\", xaxt = \"n\")\npar(new=TRUE)\nmatplot(colnames(snvdt2der2_spec), t(snvdt2der2_spec), type = \"l\",lty = 4, axes = FALSE, xlab = \" \", ylab = \" \", main = \" \", col = \"red\", bty = \"n\")\naxis(4)\naxis(1)\n\n\n\n\nFigure 4: SNVDT2 and SNVDT2 + Second Derivative compared"
  },
  {
    "objectID": "posts/NIT_tutorial_7/NIT_tutorial_7.html#checking-the-correlation-with-the-protein-parameter-for-the-math-treatments-calculated-in-this-post",
    "href": "posts/NIT_tutorial_7/NIT_tutorial_7.html#checking-the-correlation-with-the-protein-parameter-for-the-math-treatments-calculated-in-this-post",
    "title": "Near Infrared Transmitance Tutorial (part 7)",
    "section": "Checking the correlation with the protein parameter for the math-treatments calculated in this post",
    "text": "Checking the correlation with the protein parameter for the math-treatments calculated in this post\nFigure 5 compares correlation spectra for the four different options we have tried in this post. Visually it is difficult to decide which one can be the best, but they can help us to see where are the wavelength ranges more associated to the protein in this case.\n\ncor_prot_der1 <- cor(tecator$Protein, der1_spec)\nmatplot(colnames(der1_spec), t(cor_prot_der1), type = \"l\", xlab = \"wavelengths (nm)\", ylab = \"Absorbance\", main = \" \", col = \"black\", ylim = c(-1.0, 1.0))\npar(new = TRUE)\ncor_prot_snvdt2der1 <- cor(tecator$Protein, snvdt2der1_spec)\nmatplot(colnames(snvdt2der1_spec), t(cor_prot_snvdt2der1), type = \"l\", xlab = \" \", ylab = \" \", main = \" \", col = \"red\", ylim = c(-1.0, 1.0))\npar(new = TRUE)\ncor_prot_der2 <- cor(tecator$Protein, der2_spec)\nmatplot(colnames(der2_spec), t(cor_prot_der2), type = \"l\", xlab = \" \", ylab = \" \", main = \" \", col = \"blue\", ylim = c(-1.0, 1.0))\npar(new = TRUE)\ncor_prot_snvdt2der2 <- cor(tecator$Protein, snvdt2der2_spec)\nmatplot(colnames(snvdt2der2_spec), t(cor_prot_snvdt2der2), type = \"l\", xlab = \" \", ylab = \" \", main = \" \", col = \"green\", ylim = c(-1.0, 1.0))\n\n\nlegend(\"topleft\", legend = c(\"1st Der\", \"SNVDT2+1Der\", \"2nd Der\", \"SNVDT2+2Der\" ),\n       lty = 1, col = c(\"black\", \"red\", \"blue\", \"green\"))\n\n\n\n\nFigure 5: SNVDT2 and SNVDT2 + Second Derivative compared\n\n\n\n\n\n\n\n\n\n\nLet´s do it with ggplot2\n\n\n\n\n\nWe have already load tidyverse library at the beginning\n\ncor_prot_with_der <- as.data.frame(rbind(cor_prot_der1, cor_prot_snvdt2der1,                                                 cor_prot_der2, cor_prot_snvdt2der2))\n\n#replace all NA values with zero\ncor_prot_with_der <- cor_prot_with_der %>% \n                        replace(is.na(.), 0)\n\ncor_prot_with_dt <- cor_prot_with_der %>% \n  mutate(Mat_treatment = as.factor(c(\"1ª Der\", \"SNVDT2 + 1ª Der\",\n                                     \"2ª Der\", \"SNVDT2 + 2ª Der\")))\n\n\ncor_prot_with_dt %>% \n  pivot_longer(cols = c(1:100), names_to = \"Wavelength\", values_to = \"Correlation\") %>% \n  mutate(Wavelength = as.integer(Wavelength)) %>% \n  ggplot(aes(x = Wavelength, y = Correlation, group = Mat_treatment, col = Mat_treatment)) +\n  geom_line(size = 1)\n\n\n\n\n\n\n\nLet´s see in a diagram what we have seen until this post\n\n\n\n\nflowchart LR\n  A[Raw Spectra] --> B(SNV)\n  A --> C(Detrend only)\n  A --> D[SNV & linear Detrend]\n  A --> E[SNV & Quadratic Detrend]\n  D --> F[First Derivative]\n  D --> G[Second Derivative]\n  A --> H[MSC]\n  A --> I[First Derivative]\n  A --> J[Second Derivative]\n  \n\n\n\n\n\n\n\n\nWe have several options now to develop models and see which one gives the better statistics, of course there are more math treatments we can try but we stop in this tutorial with the derivatives and in the next ones we will check the different options to find outliers.\nFinally we add the new math treatments to the tecator database to use it in the coming posts:\n\ntecator$der1_spec <- der1_spec\ntecator$der2_spec <- der2_spec\ntecator$snvdt2der1_spec <- snvdt2der1_spec\ntecator$snvdt2der2_spec <- snvdt2der2_spec\n\nand save the dataframe for future use:\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws7.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_8/NIT_tutorial_8.html",
    "href": "posts/NIT_tutorial_8/NIT_tutorial_8.html",
    "title": "PCA - NIT tutorial (part 8)",
    "section": "",
    "text": "Let´s load the workspace and the libraries we are going to use:"
  },
  {
    "objectID": "posts/NIT_tutorial_8/NIT_tutorial_8.html#principal-component-analysis",
    "href": "posts/NIT_tutorial_8/NIT_tutorial_8.html#principal-component-analysis",
    "title": "PCA - NIT tutorial (part 8)",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\nWe use the spectra matrix “X” and we want to decompose it into a matrix product:"
  },
  {
    "objectID": "posts/NIT_tutorial_8/NIT_tutorial_8.html#x-tpt-e",
    "href": "posts/NIT_tutorial_8/NIT_tutorial_8.html#x-tpt-e",
    "title": "PCA - NIT tutorial (part 8)",
    "section": "\\[X = TP^{t}+ E\\]",
    "text": "\\[X = TP^{t}+ E\\]\nwhere:\n\nX is the spectra matrix (with the math treatment we have choose)\nT is a score matrix,\nP is the terms matrix and\nE is the error matrix.\n\nThere are several ways to calculate the PCA with R, but let´s start with “prcomp”. For the calculation we will use the tecator spectra with the SNV+DT2 and the second derivative, that we have seen on part 7.\n\ntecator_pc <- prcomp(tecator$snvdt2der2_spec)\nsummary(tecator_pc)[[6]][,1:10]\n\n                               PC1         PC2         PC3          PC4\nStandard deviation     0.004966548 0.001532207 0.000939981 0.0005106424\nProportion of Variance 0.869350000 0.082740000 0.031140000 0.0091900000\nCumulative Proportion  0.869350000 0.952090000 0.983230000 0.9924200000\n                                PC5         PC6         PC7          PC8\nStandard deviation     0.0003223387 0.000200553 0.000164743 0.0001470434\nProportion of Variance 0.0036600000 0.001420000 0.000960000 0.0007600000\nCumulative Proportion  0.9960800000 0.997500000 0.998460000 0.9992200000\n                                PC9         PC10\nStandard deviation     0.0001073009 6.183104e-05\nProportion of Variance 0.0004100000 1.300000e-04\nCumulative Proportion  0.9996200000 9.997600e-01\n\n\nIn the summary we can see the quantity of variance explained by every term (or principal component). We can calculate the variance in percentage and plot it.\n\npercentVariance <- round(tecator_pc$sdev^2/sum(tecator_pc$sdev^2)*100, 2)\n\nFigure 1 shows how the firsts PCs explain almost all the variance, so we can discard the rest and retain only the important ones.\n\nplot(percentVariance[1:10], type = \"b\", xlab = \"PC number\", ylab= \"% Variance explained\")\n\n\n\n\nFigure 1: Percentage Variance explained by PC\n\n\n\n\nFigure 1 The plot of the cumulative variance can give us a better idea about the number of principal components to keep:\n\nplot(cumsum(tecator_pc$sdev^2 / sum(tecator_pc$sdev^2)*100)[1:10], type=\"b\", xlab = \"PC number\", ylab = \"Cummulative Variance %\")\n\n\n\n\nFigure 2: Cumulative variance as we add a new PC\n\n\n\n\nAs we see, after 6 principal components the line becomes flat and almost 100% of the variance is explained (exactly 99.75 %). We see how the first one explain almost 87% of the variance, and the two first terms explain together more than 95% of the variance. For this reason is interesting to look to the plane formed by this two terms and see the scores. We can see this using “biplot”.\n\nbiplot(tecator_pc)\n\n\n\n\nFigure 3: Biplot with scores and loadings for PC1 vs PC2\n\n\n\n\nFigure 3 We see the samples as a black number in the plane, and the scores are the projection of those samples on the low axis (PC1), and left axis (PC2). The “loadings” are expressed as red arrow, and their projections must be done over the bottom and right axis. As we can see in the biplot of PC1 and PC2, the wavelengths between 922 and 936 have a high negative loading value for PC1, but very low for PC2.\n\nmatplot(seq(850, 1048, by = 2), tecator_pc$rotation[ , 1:2], type = \"l\", ylab = \"\", xlab = \"wavelength\", main = \"Loadings 1 and 2\", \n        col = c(\"black\", \"red\"))\nabline(h = 0)\nrect(xleft = 922, xright = 936, ybottom = -0.38, ytop = 0.21, border = \"blue\", lty = \"dashed\", lwd = 2 )\nlegend(\"topright\", legend = c(\"1st loading\", \"2nd loading\"), lty = c(1, 2), col = c(\"black\", \"red\"))\n\n\n\n\nFigure 4: Loadings 1 and 2\n\n\n\n\nFigure 4 All those arrows in the plane that we call “loadings” (100 values, one for each wavelength), can be seen better as a spectrum where we see peaks and valleys that give details about the importance of every wavelength in the Principal Component. We show the area between 922 and 936 that we have been talking about.\nLet´s see now the “biplot” for PC2 and PC3.\n\nbiplot(tecator_pc, choices = 2:3)\n\n\n\n\nFigure 5: Biplot with scores and loadings for PC2 vs PC3\n\n\n\n\nFigure 5 In the case of the plane formed by PC2 and PC3, we can see how the loadings go in almost all the directions in the plane. We can see also how some samples seems to be apart from the rest.\n\nmatplot(seq(850, 1048, by = 2), tecator_pc$rotation[ , 2:3], type = \"l\", ylab = \"\", xlab = \"wavelength\", main = \"Loadings 2 and 3\", col = c(\"red\", \"blue\"))\nlegend(\"topright\", legend = c(\"2nd loading\", \"3th loading\"), lty = c(1, 2), col = c(\"red\", \"blue\"))\n\n\n\n\nFigure 6: Loadings 2 and 3\n\n\n\n\nLooking to the “biplots” and the “loadings” we have a better idea of the importance of every wavelength to the correspondent principal component."
  },
  {
    "objectID": "posts/NIT_tutorial_8/NIT_tutorial_8.html#how-to-find-the-peaks-in-the-loading-spectrum",
    "href": "posts/NIT_tutorial_8/NIT_tutorial_8.html#how-to-find-the-peaks-in-the-loading-spectrum",
    "title": "PCA - NIT tutorial (part 8)",
    "section": "How to find the peaks in the loading spectrum?",
    "text": "How to find the peaks in the loading spectrum?\nWe can use the package {photobiology} and the function valleys for the negative peaks and find_peaks for the positive ones, doing this we can study the loadings in more detail and check if they have certain degree of relationship with the outcome variables (parameters).\nLet´s have a look to the first loading (peaks and valleys), trying to find out what explain:\n\nmatplot(seq(850, 1048, by = 2), tecator_pc$rotation[ , 1], type = \"l\", ylab = \"\", xlab = \"wavelength\", main = \"Loading 1\", col = \"black\")\n\nwhich(find_peaks(tecator_pc$rotation[ ,1]) == TRUE)\n\n 854  858  878  906  948  988 1002 1028 \n   3    5   15   29   50   70   77   90 \n\nvalleys(tecator_pc$rotation[ , 1])\n\n         892          930          972          998         1018         1036 \n-0.003496019 -0.359915187  0.023924714  0.031066416 -0.026031653 -0.045698228 \n\nabline(v = c(878, 906, 948, 1028), col = \"blue\")\nabline(v = c(892, 930, 972, 1018), col = \"green\")\n\nlegend(\"bottomleft\", legend = c(\"930....FAT\", \"948....WATER\"), lty = 1, col = c(\"green\", \"black\"))\nrect(xleft = 925, xright = 960, ybottom = -0.38, ytop = 0.21, border = \"red\", lty = \"dashed\", lwd = 2 )\n\n\n\n\nFigure 7: Interpret loadings 1 and 2 bands\n\n\n\n\nBy the literature we can know where the overtones for certain bonds like C_H, O_H or N-H are. And looking to the first loading, it seems that represents in certain way, the fat and moisture parameter. We just have to correlate the loadigs values for the first PC with the three parameters and see the high correlation with fat and moisture.\n\ncor(tecator$Moisture, tecator_pc$x[ , 1])\n\n[1] -0.9777829\n\ncor(tecator$Fat, tecator_pc$x[ , 1])\n\n[1] 0.9823003\n\ncor(tecator$Protein, tecator_pc$x[ , 1])\n\n[1] -0.829764\n\n\nAs we have seen in previous posts fat and protein are inverse correlated, and that is the reason we have a negative high correlation for the protein with this first loading.\nWe can see the XY plots for the reference values vs. the first loading values.\n\nplot(tecator$Moisture, tecator_pc$x[ , 1], xlab = \"Moisture\", ylab = \"PC1  response\", main = \"Moisture vs PC1\")\n\n\n\n\nFigure 8: correlating Moisture with scores for loading 1\n\n\n\n\n\nplot(tecator$Fat, tecator_pc$x[ , 1], xlab = \"Fat\", ylab = \"First loading response\", main = \"Fat vs PC1\")\n\n\n\n\nFigure 9: correlating Fat with scores for loading 1\n\n\n\n\n\nplot(tecator$Protein, tecator_pc$x[ , 1], xlab = \"Protein\", ylab = \"First loading response\", main = \"Protein vs PC1\")\n\n\n\n\nFigure 10: correlating Protein with scores for loading 1\n\n\n\n\nAs we study more loadings we still see the bands which correspond to fat, water or protein, but the correlation with the reference values is less, but this is normal due that the highest extraction was taken by the first principal component and we are extracting from the remaining new variability that we want to interpret.\nAs we see, there is certain correlation between the PC loadings and the parameters, so we can develop a regression called “principal components regression” to predict the values of new samples. So this is something we can do in coming posts.\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws8.RData\")"
  },
  {
    "objectID": "posts/NIT_tutorial_9/NIT_tutorial_9.html",
    "href": "posts/NIT_tutorial_9/NIT_tutorial_9.html",
    "title": "PCA - NIT tutorial (part 9)",
    "section": "",
    "text": "As always, we load first our work space to continue from the previous post\nNow we load the libraries we are going to use:\nWe continue exploring the Principal Component Analysis, trying to understand as best as possible our data set. One of the arguments we get from the “prcomp” calculation is the x matrix, ans with this matrix we can have a look to the map of scores for the first three PCs."
  },
  {
    "objectID": "posts/NIT_tutorial_9/NIT_tutorial_9.html#checking-the-scores-maps",
    "href": "posts/NIT_tutorial_9/NIT_tutorial_9.html#checking-the-scores-maps",
    "title": "PCA - NIT tutorial (part 9)",
    "section": "Checking the scores maps",
    "text": "Checking the scores maps\nWe can order the samples by their parameter content and assigning a color scale check the distribution of the samples in the scores map, in this case the distribution of fat , moisture and protein:\n\n\n\n\n\nFigure 1: Distributions of scores on PC1 and PC2 vs. their fat content\n\n\n\n\n\n\n\n\n\nFigure 2: Distributions of scores on PC1 and PC2 vs. their moisture content\n\n\n\n\n\n\n\n\n\nFigure 3: Distributions of scores on PC1 and PC2 vs. their protein content\n\n\n\n\nOnce again with these plots we see how the parameter fat has a negative correlation with the moisture and protein parameters."
  },
  {
    "objectID": "posts/NIT_tutorial_9/NIT_tutorial_9.html#checking-the-spectra-wavelengths",
    "href": "posts/NIT_tutorial_9/NIT_tutorial_9.html#checking-the-spectra-wavelengths",
    "title": "PCA - NIT tutorial (part 9)",
    "section": "Checking the spectra wavelengths",
    "text": "Checking the spectra wavelengths\nAnother option is to check if, with these color palettes, we can see the wavelengths or wavelengths areas which are more important for every parameter.\n\n\n\n\n\nFigure 4: Relationship between the spectra bands and fat\n\n\n\n\n\n\n\n\n\nFigure 5: Relationship between the spectra bands and moisture\n\n\n\n\n\n\n\n\n\nFigure 6: Relationship between the spectra bands and protein\n\n\n\n\nIn Figure 4 we can see the positive correlation between the 930 nm band and the fat content. In Figure 5 all the area between 950 and 1000nm seems to be correlated with moisture. Finally in the Figure 6 we can see certain areas where there is a positive correlation, but we will try to see it better with other math treatments.\n\nsave.image(\"C:/BLOG/Workspaces/NIT Tutorial/NIT_ws9.RData\")"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nI am using Quarto to develop a new blog about the use of R and its chemometric tools applyed to the Near Infared spectroscopy. Hope you enjoyed the coming posts in the future."
  }
]